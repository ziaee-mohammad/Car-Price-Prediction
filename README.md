# ğŸš— Car Price Prediction

An endâ€‘toâ€‘end **regression** project to predict **used car prices** from tabular attributes (make/model, year, mileage, engine specs, fuel type, transmission, etc.).  
Includes clean preprocessing pipelines, feature engineering, model training (Linear Regression, Random Forest, XGBoost), and rigorous evaluation (**MAE, RMSE, RÂ², MAPE**).

---

## ğŸ“– Overview
This repository demonstrates best practices for **tabular regression**:
- Leakageâ€‘safe pipelines with `ColumnTransformer` + `Pipeline`
- Robust handling of categorical & numerical features
- Crossâ€‘validated model selection and error analysis
- Exportable artifacts for inference

---

## ğŸ—‚ï¸ Dataset
Typical CSV layout under `data/`:
```
data/
â”œâ”€ train.csv
â””â”€ test.csv
```
**Columns (examples):** `price`, `make`, `model`, `year`, `mileage`, `engine`, `power`, `fuel`, `transmission`, `owner`, `city`, `features...`

> Ensure target column is named `price` (or update code accordingly). Clean outliers and inconsistent units (e.g., mileage km vs mi).

---

## ğŸ”§ Preprocessing & Feature Engineering
- **Imputation**: numeric (median), categorical (most frequent)
- **Scaling**: Standardize numerical features
- **Encoding**: Oneâ€‘hot for categoricals (`handle_unknown="ignore"`)
- **Domain features**: car **age** (`current_year - year`), logâ€‘price, mileage buckets
- **Optional**: Target encoding (inside CV), interaction terms

All steps live **inside** `Pipeline` to avoid leakage.

---

## ğŸ§  Models
- **Linear Regression / Ridge / Lasso** â€” fast baselines
- **Random Forest Regressor** â€” nonâ€‘linear baseline
- **XGBoost Regressor** â€” strong tabular learner
- *(Optional)* LightGBM / CatBoost

---

## ğŸ“ˆ Evaluation
Primary metrics:
- **MAE** â€” median error magnitude
- **RMSE** â€” penalizes large errors
- **RÂ²** â€” explained variance
- **MAPE** â€” relative error (watch for zero/nearâ€‘zero prices)

**Error analysis**:
- Residual plots vs. mileage/age
- Feature importance (treeâ€‘based models)
- Price distribution before/after cleaning

---

## ğŸ§© Repository Structure (suggested)
```
Car-Price-Prediction/
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_eda.ipynb
â”‚  â”œâ”€ 02_training_baselines.ipynb
â”‚  â”œâ”€ 03_error_analysis.ipynb
â”œâ”€ src/
â”‚  â”œâ”€ data.py          # loading/splitting; type casting
â”‚  â”œâ”€ features.py      # preprocessors & domain features
â”‚  â”œâ”€ models.py        # model builders (linreg/RF/XGB)
â”‚  â”œâ”€ train.py         # CV + fit
â”‚  â”œâ”€ eval.py          # metrics & plots
â”‚  â””â”€ infer.py         # singleâ€‘row inference
â”œâ”€ reports/figures/    # residuals, importances, distributions
â”œâ”€ data/               # (gitignored)
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## âš™ï¸ Setup & Usage
1) **Clone & install**
```bash
git clone https://github.com/ziaee-mohammad/Car-Price-Prediction.git
cd Car-Price-Prediction
pip install -r requirements.txt
```

2) **Run notebooks**
```bash
jupyter notebook
```

3) **(Optional) Scripts**
```bash
python -m src.train --model xgboost
python -m src.eval  --report
python -m src.infer --json '{"make":"Toyota","model":"Corolla","year":2018,"mileage":65000,"fuel":"Petrol","transmission":"Manual"}'
```

---

## ğŸ“¦ Requirements (example)
```
pandas
numpy
scikit-learn
xgboost
matplotlib
seaborn
```

---

## âœ… Good Practices
- Remove duplicates & extreme outliers (e.g., price < 500 or > 200,000 as per market)
- Normalize freeâ€‘text fields (model trims/variants)
- Use consistent currency; document exchange rate if converted
- Logâ€‘transform price if heavyâ€‘tailed, and inverseâ€‘transform predictions

---

## ğŸ· Tags
```
data-science
machine-learning
regression
tabular-data
feature-engineering
model-evaluation
xgboost
python
jupyter-notebook
```

---

## ğŸ‘¤ Author
**Mohammad Ziaee** â€” Computer Engineer | AI & Data Science  
ğŸ“§ moha2012zia@gmail.com  
ğŸ”— https://github.com/ziaee-mohammad
ğŸ‘‰ Instagram: [@ziaee_mohammad](https://www.instagram.com/ziaee_mohammad/)
---

## ğŸ“œ License
MIT â€” free to use and adapt with attribution.
